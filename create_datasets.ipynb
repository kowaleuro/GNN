{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import yaml\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define destination for the generated samples\n",
    "dataset_path = \"dataset\"\n",
    "#paths relative to data folder\n",
    "\n",
    "\n",
    "# ---------------ORIGINAL------------------------\n",
    "original_directory = 'original'\n",
    "graphs_path = os.path.join(original_directory,\"graphs\")\n",
    "routings_path = os.path.join(original_directory,\"routings\")\n",
    "tm_path =  os.path.join(original_directory,\"tm_extracted\")\n",
    "\n",
    "\n",
    "# ---------------------PREDICTION-------------------\n",
    "prediction_directory = 'prediction'\n",
    "graphs_pred_path = os.path.join(prediction_directory,'graphs')\n",
    "routings_pred_path = os.path.join(prediction_directory,'routings')\n",
    "tm_pred_path = os.path.join(prediction_directory,'tm')\n",
    "pkts_info = os.path.join(prediction_directory,'pkts_info')\n",
    "\n",
    "# ---------------------SIM-------------------\n",
    "simulation_directory = 'simulation'\n",
    "graphs_sim_path = os.path.join(simulation_directory,'graphs')\n",
    "routings_sim_path = os.path.join(simulation_directory,'routings')\n",
    "tm_sim_path = os.path.join(simulation_directory,'tm')\n",
    "simulation_file = os.path.join(simulation_directory, 'simulation.txt')\n",
    "# Path to simulator file\n",
    "try:\n",
    "    os.chdir(f\"{os.getcwd()}/{dataset_path}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(os.path.join(simulation_directory,'results'))\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(simulation_directory,'tmp'))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(prediction_directory,exist_ok=True)\n",
    "os.makedirs(pkts_info,exist_ok=True)\n",
    "os.makedirs(graphs_pred_path,exist_ok=True)\n",
    "os.makedirs(routings_pred_path,exist_ok=True)\n",
    "os.makedirs(simulation_directory,exist_ok=True)\n",
    "os.makedirs(graphs_sim_path,exist_ok=True)\n",
    "os.makedirs(routings_sim_path,exist_ok=True)\n",
    "os.makedirs(tm_sim_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph(graphs: list, path: str):\n",
    "    for graph_filename, graph in graphs.items():\n",
    "        f = os.path.join(path, graph_filename)\n",
    "        if not os.path.isfile(f):\n",
    "            # Creates a new file\n",
    "            with open(f, 'w') as _:\n",
    "                pass\n",
    "        nx.write_gml(graph,f)\n",
    "\n",
    "def modify_band(graph: nx.DiGraph):\n",
    "    for edge in graph.edges(data=True):\n",
    "        params = edge[2]\n",
    "        params['bandwidth'] = int(params['bandwidth'] / 1000)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_sim = {}\n",
    "graphs = {}\n",
    "\n",
    "buffer = 32_000\n",
    "\n",
    "for filename in os.listdir(graphs_path):\n",
    "    f = os.path.join(graphs_path, filename)\n",
    "    graph = nx.read_gml(f)\n",
    "    graph = modify_band(graph)\n",
    "    graphs[filename] = graph\n",
    "    if filename[0] == 'g':\n",
    "        sim_graph = graph.to_undirected()\n",
    "        sim_graph = nx.Graph(sim_graph)\n",
    "        nx.set_node_attributes(sim_graph, buffer, \"bufferSizes\")\n",
    "        graphs_sim[filename] = sim_graph\n",
    "\n",
    "\n",
    "write_graph(graphs_sim,graphs_sim_path)\n",
    "write_graph(graphs,graphs_pred_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(routings_path):\n",
    "    f = os.path.join(routings_path, filename)\n",
    "    os.popen(f'copy {f} {os.path.join(routings_pred_path,filename)}')\n",
    "    if filename[0] == 'R':\n",
    "        new = os.path.join(routings_sim_path, filename)\n",
    "        lines = []\n",
    "        with open(f, 'r') as fd:\n",
    "            for line in fd:\n",
    "                lines.append(line.replace(' ',','))\n",
    "        with open(new, 'w') as fd:\n",
    "            for line in lines:\n",
    "                fd.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TM\n",
    "- Multi Burst (MB) flow:\n",
    "- Packet size in bytes\n",
    "- Bandwidth rate in bps during the burst\n",
    "- Number of packets of each burst\n",
    "- Number of burst during the experiment (this value can be ignored)\n",
    "- Inter burst gap in microseconds\n",
    "- Inter stream gap in microseconds. Time to start the first burst. Always 0 for these datasets.\n",
    "- ToS. Always 0 for these datasets.\n",
    "\n",
    "/////////////\n",
    "\n",
    "Constant Bit Rate (CBR) flow:\n",
    "- Packet size in bytes\n",
    "- Bandwidth rate in bps\n",
    "- ToS. Always 0 for these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tarfile(output_filepath: os.path, path_list: list):\n",
    "    with tarfile.open(output_filepath, \"w:gz\") as tar:\n",
    "        for path in path_list:\n",
    "            tar.add(path, arcname=os.path.join(os.path.basename(output_filepath)[:-7],os.path.basename(path)))\n",
    "\n",
    "def complete_sim_file(sim_file: os.path,filepath: os.path):\n",
    "    data = pd.read_csv(filepath, sep=\";\",header=None,dtype=\"string\")\n",
    "    with open(sim_file, 'a') as file:\n",
    "        for _, row in data.iterrows():\n",
    "            g = f'graphs/{row[1]}'\n",
    "            r = f'routings/{row[2]}'\n",
    "            t = f'tm/tm-{row[0]}.txt'\n",
    "            file.write(f'{g},{r},{t}\\n')\n",
    "\n",
    "def convert_line(line: str):\n",
    "    sign_pos = line.find('|')\n",
    "    line_start = '10,' + line[:sign_pos + 1]\n",
    "    res_table = line[sign_pos + 1:].split(';')\n",
    "\n",
    "    for ii, entry in enumerate(res_table):\n",
    "        flow_measures = entry.split(',')\n",
    "        flow_measures[0] = str(float(flow_measures[0]) * 1000)\n",
    "        for i in range(8):\n",
    "            flow_measures.append('0')\n",
    "            res_table[ii] = ','.join(flow_measures)\n",
    "    return '\\n' + line_start + ';'.join(res_table) +';'\n",
    "\n",
    "def check_sim_results(dataset_name: str, orignal_input_file_lines: list):\n",
    "    with open(os.path.join(prediction_directory,'experimentResults.txt'), 'w',encoding='utf-8',newline='\\n') as file:\n",
    "        pass\n",
    "    with open(os.path.join(prediction_directory,'input_files.txt'), 'w',encoding='utf-8',newline='\\n') as file:\n",
    "        pass\n",
    "    results_dir = os.path.join(simulation_directory,'results',dataset_name)\n",
    "\n",
    "    initial_line = True\n",
    "    for filename in os.listdir(results_dir):\n",
    "        f = os.path.join(results_dir, filename)\n",
    "        if os.path.isfile(f) and '.tar.gz' in f:\n",
    "            tar = tarfile.open(f, 'r:gz')\n",
    "            dir_info = tar.next()\n",
    "            results_file = tar.extractfile(dir_info.name+\"/simulationResults.txt\")\n",
    "\n",
    "            results_lines = []\n",
    "            while (True):\n",
    "                results_line = results_file.readline().decode()[:-2]\n",
    "                if (len(results_line) == 0):\n",
    "                    break\n",
    "                results_lines.append(convert_line(results_line))\n",
    "\n",
    "            if initial_line:\n",
    "                results_lines[0] = results_lines[0][1:]\n",
    "                initial_line = False\n",
    "\n",
    "            with open(os.path.join(prediction_directory,'experimentResults.txt'), 'a',encoding='utf-8',newline='\\n') as file:\n",
    "                for entry in results_lines:\n",
    "                    file.write(entry)\n",
    "\n",
    "            input_file = tar.extractfile(dir_info.name+\"/input_files.txt\")\n",
    "            results_lines = []\n",
    "            while (True):\n",
    "                results_line = input_file.readline().decode()\n",
    "                if (len(results_line) == 0):\n",
    "                    break\n",
    "                pos = results_line.find(';')\n",
    "                index = int(results_line[0:pos])\n",
    "                results_lines.append(orignal_input_file_lines[index])\n",
    "            with open(os.path.join(prediction_directory,'input_files.txt'), 'a',encoding='utf-8',newline='\\n') as file:\n",
    "                for entry in results_lines:\n",
    "                    file.write(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yaml_config(dataset_name: str):\n",
    "    conf_file = os.path.join(simulation_directory,\"conf.yml\")\n",
    "    conf_parameters = {\n",
    "        \"threads\": 6,# Number of threads to use \n",
    "        \"dataset_name\": dataset_name, # Name of the dataset. It is created in <training_dataset_path>/results/<name>\n",
    "        \"samples_per_file\": 10, # Number of samples per compressed file\n",
    "        \"rm_prev_results\": \"n\", # If 'y' is selected and the results folder already exists, the folder is removed.\n",
    "        \"write_pkt_info\": \"n\", # If 'y' is selected, a file per simulation is created in the pkts_info folder of the dataset. This file contain a line per packet with the following data: src_id dst_id flow_id tos timestamp(ns) pkt_size[ delay(ns)]\n",
    "    }\n",
    "\n",
    "    with open(conf_file, 'w') as fd:\n",
    "        yaml.dump(conf_parameters, fd)\n",
    "\n",
    "def dest_path():\n",
    "    graphs_path = \"graphs\"\n",
    "    routings_path = \"routings\"\n",
    "    tm_path = \"tm\"\n",
    "    if os.path.isdir(simulation_directory):\n",
    "        print (\"Destination path already exists. Files within the directory may be overwritten.\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(simulation_directory,graphs_path))\n",
    "        os.mkdir(os.path.join(simulation_directory,routings_path))\n",
    "        os.mkdir(os.path.join(simulation_directory,tm_path))\n",
    "\n",
    "def docker_cmd_run(training_dataset_path):\n",
    "    raw_cmd = f\"docker run --rm --mount type=bind,src={os.path.join(os.getcwd(),training_dataset_path)},dst=/data bnnupc/bnnetsimulator\"\n",
    "    terminal_cmd = raw_cmd\n",
    "    if os.name != 'nt': # Unix, requires sudo\n",
    "        print(\"Superuser privileges are required to run docker. Introduce sudo password when prompted\")\n",
    "        terminal_cmd = f\"echo {getpass()} | sudo -S \" + raw_cmd\n",
    "        raw_cmd = \"sudo \" + raw_cmd\n",
    "    print(raw_cmd)\n",
    "    !{terminal_cmd}\n",
    "    return raw_cmd, terminal_cmd\n",
    "\n",
    "def run_sim(dataset_name:str):\n",
    "\n",
    "    yaml_config(dataset_name)\n",
    "    # dest_path()\n",
    "    docker_cmd_run(simulation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:23: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:23: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:0: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:6: Error using traffic matrix file /data/tm/tm-456.txt at line 44. Average bandwidth of the path should be bigger than 10: 6.0 \n",
      "INFO:root:5: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:0: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:22: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:3: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:23: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:24: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:3: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:21: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:2: Error using traffic matrix file /data/tm/tm-652.txt at line 17. Average bandwidth of the path should be bigger than 10: 8.0 \n",
      "INFO:root:4: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:5: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:22: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:21: OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm --mount type=bind,src=d:\\GNN\\dataset\\simulation,dst=/data bnnupc/bnnetsimulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:5: OK\n",
      "INFO:root:0: OK\n",
      "INFO:root:4: OK\n",
      "INFO:root:2: OK\n",
      "INFO:root:3: OK\n",
      "INFO:root:6: OK\n",
      "INFO:root:1: OK\n",
      "INFO:root:9: OK\n",
      "INFO:root:7: OK\n",
      "INFO:root:8: OK\n",
      "INFO:root:10: OK\n",
      "INFO:root:15: OK\n",
      "INFO:root:12: OK\n",
      "INFO:root:11: OK\n",
      "INFO:root:14: OK\n",
      "INFO:root:13: OK\n",
      "INFO:root:19: OK\n",
      "INFO:root:20: OK\n",
      "INFO:root:16: OK\n",
      "INFO:root:18: OK\n",
      "INFO:root:17: OK\n",
      "INFO:root:23: OK\n",
      "INFO:root:21: OK\n",
      "INFO:root:24: OK\n",
      "INFO:root:22: OK\n"
     ]
    }
   ],
   "source": [
    "# parameter to reduce badnwith to have feasible simulation time\n",
    "band_param = 10000\n",
    "\n",
    "my_cols = ['src','dst','packet_size','avg_band','no_of_packetrs','no_of_bursts','burst gap','stream gap','ToS']\n",
    "\n",
    "counter = 375\n",
    "for filename in os.listdir(original_directory):\n",
    "    f = os.path.join(original_directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        with open(simulation_file,'w'):\n",
    "            pass\n",
    "        os.makedirs(tm_pred_path,exist_ok=True)\n",
    "        tm_dir = os.path.join(original_directory,filename[:-7],filename[:-7],'tm')\n",
    "        if not os.path.isdir(tm_dir):\n",
    "            file = tarfile.open(f)\n",
    "            file.extractall(f[:-7])\n",
    "        for tm_file_name in os.listdir(tm_dir):\n",
    "            tm_file = os.path.join(tm_dir, tm_file_name)\n",
    "            data = pd.read_csv(tm_file, sep=\",|;\",header=None,names=my_cols,dtype=\"string\",engine='python')\n",
    "            max_load = data['src'][0]\n",
    "            data['avg_band'] = data['avg_band'].astype('Float64')\n",
    "            data = data[1:]\n",
    "            data['avg_band'] = data['avg_band'] / band_param\n",
    "\n",
    "            tm_data = data.copy()\n",
    "            tm_data.insert(0,\"src_dst_size\",tm_data.src.str.cat([tm_data.dst,tm_data.packet_size],sep=';'))\n",
    "            tm_data = tm_data.drop(columns=['src','dst','packet_size'])\n",
    "            pred_file = os.path.join(tm_pred_path, f'tm-{counter}.txt')\n",
    "            tm_data.to_csv(pred_file,header=False,index=False,encoding='utf-8')\n",
    "\n",
    "            with open(pred_file, 'r',encoding='utf-8',newline='\\n') as file: \n",
    "                lines = file.readlines() \n",
    "\n",
    "            with open(pred_file, 'w',encoding='utf-8',newline='\\n') as file:\n",
    "                file.write(max_load + '\\n')\n",
    "                for line in lines:\n",
    "                    file.write(\"\\n\".join(line.splitlines())+ '\\n')\n",
    "\n",
    "            new_df = pd.DataFrame(columns=['src','dst','avg_band','packet_size','ToS'])\n",
    "            new_df['src'] = data.src\n",
    "            new_df['dst'] = data.dst\n",
    "            new_df['avg_band'] = data['avg_band']\n",
    "            new_df['packet_size'] = data['packet_size']\n",
    "            new_df['ToS'] = data['ToS']\n",
    "            new_df.insert(3,\"time_distribution\",'0')\n",
    "            new_df.insert(4,\"pkt_dist\",'0')\n",
    "            new_df.insert(6,\"prob_n\",'1')\n",
    "\n",
    "            new_df.avg_band = np.ceil(new_df.avg_band).astype(int)\n",
    "            sim_file = os.path.join(tm_sim_path, f'tm-{counter}.txt')\n",
    "            new_df.to_csv(sim_file,header=False,index=False)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        tar_file = os.path.join(f[:-7],filename[:-7])\n",
    "        orig_input_file = os.path.join(tar_file,'input_files.txt')\n",
    "\n",
    "        orignal_input_file_lines = []\n",
    "        with open(orig_input_file, 'r',encoding='utf-8',newline='\\n') as file: \n",
    "            orignal_input_file_lines = file.readlines() \n",
    "\n",
    "        complete_sim_file(simulation_file,orig_input_file)\n",
    "\n",
    "        \n",
    "        # ///////////\n",
    "        \n",
    "        run_sim(filename[:-7])\n",
    "\n",
    "\n",
    "        check_sim_results(filename[:-7],orignal_input_file_lines)\n",
    "        exp_results = os.path.join(prediction_directory,'experimentResults.txt')\n",
    "        pred_input = os.path.join(prediction_directory,'input_files.txt')\n",
    "        path_list = [tm_pred_path,exp_results,pred_input]\n",
    "        rar_name = os.path.join(prediction_directory,filename)\n",
    "        make_tarfile(rar_name,path_list)\n",
    "        shutil.rmtree(tm_pred_path)\n",
    "        os.remove(exp_results)\n",
    "        os.remove(pred_input)\n",
    "        shutil.rmtree(f[:-7])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
